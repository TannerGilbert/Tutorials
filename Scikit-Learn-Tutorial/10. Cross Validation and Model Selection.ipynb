{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Tutorial #10 - Cross Validation and Model Selection\n",
    "![Scikit Learn Logo](http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Model Selection?\n",
    "\n",
    "Model Selection is the process of choosing one model over the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  label\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'label'])\n",
    "le = LabelEncoder()\n",
    "iris['label'] = le.fit_transform(iris['label'])\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(iris.drop(['label'], axis=1))\n",
    "y = np.array(iris['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = [\n",
    "    ('LR', LogisticRegression()),\n",
    "    ('NB', GaussianNB()),\n",
    "    ('SVM', SVC()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('DT', DecisionTreeClassifier()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.9666666666666667\n",
      "NB 0.9666666666666667\n",
      "SVM 1.0\n",
      "KNN 0.9833333333333333\n",
      "DT 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "for name, model in models:\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        print(name, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "In the example above we used <i>train_test_split</i> to create our training and testing set eventhough this is a totaly legit method of doing so it has a few drawbacks. Because we are splitting the original dataset we have less data to train on which could be a problem. A solution to this problem is a procedure called cross-validation (CV for short). A basic approach of CV called k-fold CV works as followed.\n",
    "\n",
    "1. The dataset is split into k smaller sets\n",
    "2. A model is trained using k-1 of the folds(smaller sets) as training data\n",
    "3. The remaining fold is used for validation\n",
    "4. Step 2 and 3 are repeated until all folds where used for validation once.\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach doesn't \"waste data\" but it is a lot more computationally expensive than something like <i>train_test_split</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.96666667, 0.93333333, 0.9       , 1.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the scoring parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.96658312, 0.93333333, 0.89769821, 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use more than one scoring method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0010004 , 0.00100017, 0.00099993, 0.00100017, 0.        ]),\n",
       " 'score_time': array([0.00099969, 0.00099969, 0.00100017, 0.00099993, 0.00200009]),\n",
       " 'test_precision_macro': array([1.        , 0.96969697, 0.93333333, 0.92307692, 1.        ]),\n",
       " 'test_recall_macro': array([1.        , 0.96666667, 0.93333333, 0.9       , 1.        ])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate # allows us to use multiple scoring metrics\n",
    "#from sklearn.metrics import recall_score\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(clf, X, y, cv=5, scoring=scoring, \n",
    "                          return_train_score=False) # cv can also return train score but we set it to false\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.4 3.9 1.7 0.4]]\n",
      "[[4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [4.6 3.4 1.4 0.3]]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train, test in kfold.split(X):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"http://scikit-learn.org/stable/modules/cross_validation.html\">Cross Validation (Scikit Learn Documentation)</a></li>\n",
    "    <li><a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\">Cross Validation (Wikipedia)</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "That was a quick overview of model selection and cross validation and how to implement them in Scikit Learn. \n",
    "I hope you liked this tutorial if you did consider subscribing on my <a href=\"https://www.youtube.com/channel/UCBOKpYBjPe2kD8FSvGRhJwA\">Youtube Channel</a> or following me on Social Media. If you have any question feel free to contact me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
